{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Delta021/Bill-Data-Extraction-API/blob/main/Main_App.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import io\n",
        "import requests\n",
        "import uvicorn\n",
        "import logging\n",
        "from typing import List\n",
        "from fastapi import FastAPI, HTTPException\n",
        "from fastapi.middleware.cors import CORSMiddleware\n",
        "from dotenv import load_dotenv\n",
        "import google.generativeai as genai\n",
        "from pdf2image import convert_from_bytes\n",
        "from PIL import Image\n",
        "\n",
        "# Import models\n",
        "from models import ExtractRequest, ExtractResponse, TokenUsage, ExtractedData, PageLineItems, BillItem\n",
        "\n",
        "# Load environment variables\n",
        "load_dotenv()\n",
        "\n",
        "# Configuration\n",
        "API_KEY = os.getenv(\"GOOGLE_API_KEY\")\n",
        "if not API_KEY:\n",
        "    raise ValueError(\"GOOGLE_API_KEY is not set in environment variables\")\n",
        "\n",
        "genai.configure(api_key=API_KEY)\n",
        "\n",
        "# Initialize FastAPI\n",
        "app = FastAPI(title=\"Bajaj Health Datathon - Bill Extractor\")\n",
        "\n",
        "app.add_middleware(\n",
        "    CORSMiddleware,\n",
        "    allow_origins=[\"*\"],\n",
        "    allow_credentials=True,\n",
        "    allow_methods=[\"*\"],\n",
        "    allow_headers=[\"*\"],\n",
        ")\n",
        "\n",
        "# Initialize Gemini Model\n",
        "# We use 'gemini-1.5-flash' for speed and cost-efficiency with high accuracy on tabular data\n",
        "model = genai.GenerativeModel('gemini-1.5-flash', generation_config={\"response_mime_type\": \"application/json\"})\n",
        "\n",
        "def download_file(url: str) -> bytes:\n",
        "    \"\"\"Downloads the file from the provided URL.\"\"\"\n",
        "    try:\n",
        "        response = requests.get(url, timeout=10)\n",
        "        response.raise_for_status()\n",
        "        return response.content\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        raise HTTPException(status_code=400, detail=f\"Failed to download document: {str(e)}\")\n",
        "\n",
        "def process_document(file_bytes: bytes, content_type: str = \"application/pdf\") -> List[Image.Image]:\n",
        "    \"\"\"Converts PDF bytes to a list of PIL Images. If image, returns list containing single image.\"\"\"\n",
        "    try:\n",
        "        # Check header to see if it is actually a PDF\n",
        "        if file_bytes.startswith(b'%PDF'):\n",
        "            return convert_from_bytes(file_bytes)\n",
        "        else:\n",
        "            # Assume it's an image\n",
        "            return [Image.open(io.BytesIO(file_bytes))]\n",
        "    except Exception as e:\n",
        "        raise HTTPException(status_code=400, detail=f\"Failed to process file format: {str(e)}\")\n",
        "\n",
        "def construct_prompt() -> str:\n",
        "    \"\"\"Constructs the strict system prompt for the LLM.\"\"\"\n",
        "    return \"\"\"\n",
        "    You are an expert AI Invoice Auditor. Your task is to extract line item details from medical or retail bills with extreme precision.\n",
        "\n",
        "    RULES FOR EXTRACTION:\n",
        "    1. **Iterate Page by Page**: Analyze each image provided.\n",
        "    2. **Classify Page Type**: Determine if the page is 'Bill Detail' (contains list of items), 'Pharmacy' (medicine list), or 'Final Bill' (summary page).\n",
        "    3. **Extract Line Items**:\n",
        "       - Extract 'item_name', 'item_amount', 'item_rate', and 'item_quantity'.\n",
        "       - If 'item_quantity' is missing, default to 1.0.\n",
        "       - If 'item_rate' is missing, infer it from amount/quantity or set to amount.\n",
        "       - Ensure 'item_amount' is the Net Amount (after discount).\n",
        "    4. **Double Counting Prevention**:\n",
        "       - If a 'Final Bill' page only summarizes categories (e.g., \"Pharmacy Total\", \"Consultation Total\") that were already listed in detail on previous pages, DO NOT treat them as new line items.\n",
        "       - Only extract granular line items.\n",
        "    5. **Output Format**:\n",
        "       - Return JSON matching exactly the requested schema.\n",
        "       - Ensure all numbers are floats/integers, no currency symbols.\n",
        "    \"\"\"\n",
        "\n",
        "@app.post(\"/extract-bill-data\", response_model=ExtractResponse)\n",
        "async def extract_bill_data(request: ExtractRequest):\n",
        "    try:\n",
        "        # 1. Download Document\n",
        "        file_bytes = download_file(request.document)\n",
        "\n",
        "        # 2. Convert to Images (Gemini handles images natively)\n",
        "        images = process_document(file_bytes)\n",
        "\n",
        "        # 3. Prepare Prompt\n",
        "        prompt_text = construct_prompt()\n",
        "\n",
        "        # 4. Call Gemini API\n",
        "        # We pass the prompt + all images of the pages\n",
        "        inputs = [prompt_text] + images\n",
        "\n",
        "        # We force the response schema to match our Pydantic model structure\n",
        "        response = model.generate_content(\n",
        "            inputs,\n",
        "            generation_config=genai.GenerationConfig(\n",
        "                response_mime_type=\"application/json\",\n",
        "                response_schema=ExtractedData\n",
        "            )\n",
        "        )\n",
        "\n",
        "        # 5. Parse Response\n",
        "        # Gemini with response_schema returns a JSON string that matches the schema\n",
        "        import json\n",
        "        llm_output = json.loads(response.text)\n",
        "\n",
        "        # 6. Calculate Usage (Approximate if not provided perfectly by preview API)\n",
        "        # Note: In production, use response.usage_metadata\n",
        "        usage = response.usage_metadata\n",
        "        token_usage = TokenUsage(\n",
        "            total_tokens=usage.total_token_count,\n",
        "            input_tokens=usage.prompt_token_count,\n",
        "            output_tokens=usage.candidates_token_count\n",
        "        )\n",
        "\n",
        "        # 7. Construct Final Response\n",
        "        # We validate the LLM output against our internal model to ensure safety\n",
        "        validated_data = ExtractedData(**llm_output)\n",
        "\n",
        "        return ExtractResponse(\n",
        "            is_success=True,\n",
        "            token_usage=token_usage,\n",
        "            data=validated_data\n",
        "        )\n",
        "\n",
        "    except Exception as e:\n",
        "        # In case of failure, we still need to return a valid HTTP response,\n",
        "        # but for the purpose of this API signature, if it crashes,\n",
        "        # we return 500. You might want to return is_success=False in a 200 OK\n",
        "        # depending on strict requirements, but standard REST is 500 on crash.\n",
        "        logging.error(f\"Error processing request: {str(e)}\")\n",
        "        raise HTTPException(status_code=500, detail=str(e))\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    uvicorn.run(\"main:app\", host=\"0.0.0.0\", port=8000, reload=True)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "id": "Guem5lEuHJwQ"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}